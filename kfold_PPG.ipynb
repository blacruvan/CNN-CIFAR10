{"cells":[{"cell_type":"markdown","metadata":{"id":"dbIzUsii9l4l"},"source":["*   **Data Preparation:**\n","    \n","    *   Use any small dataset of your choice from `torchvision`, such as CIFAR-10.\n","    *   Prepare data loaders using `torch.utils.data.DataLoader`.\n","*   **k-Fold Cross-Validation Implementation:**\n","    \n","    *   Create a function that implements k-fold cross-validation.\n","    *   Split the dataset into k folds, training on k-1 folds, and testing on the remaining fold.\n","    *   Compute the accuracy of the model for each fold.\n","*   **Network Definition:**\n","    \n","    *   Define a simple neural network with at least one hidden layer using `torch.nn.Module`.\n","*   **Training and Evaluation:**\n","    \n","    *   For each fold, train the model on the training data and evaluate on the validation data.\n","    *   Report the mean and standard deviation of the accuracy across all folds."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16558,"status":"ok","timestamp":1714767131479,"user":{"displayName":"Pedro Patiño Garcia","userId":"11861007922219825640"},"user_tz":-120},"id":"Rziooxdt9l4p","outputId":"d196efe5-a9a4-4849-f674-494689a705dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["100.0%\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data\\cifar-10-python.tar.gz to ./data\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, Subset\n","from sklearn.model_selection import KFold\n","import numpy as np\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1714767131480,"user":{"displayName":"Pedro Patiño Garcia","userId":"11861007922219825640"},"user_tz":-120},"id":"rMAytW-U9l4r"},"outputs":[],"source":["class SimpleNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleNN, self).__init__()\n","        self.fc1 = nn.Linear(32 * 32 * 3, 128)\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, 10)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 32 * 32 * 3)\n","        x = torch.relu(self.fc1(x))\n","        x = torch.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":425},"executionInfo":{"elapsed":377982,"status":"error","timestamp":1714767509455,"user":{"displayName":"Pedro Patiño Garcia","userId":"11861007922219825640"},"user_tz":-120},"id":"skK3uu0pybKb","outputId":"84e37ff2-85b4-4163-8324-52437e25282c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold Accuracy: 50.29%\n","Fold Accuracy: 49.28%\n","Fold Accuracy: 51.17%\n","Fold Accuracy: 50.2%\n","Fold Accuracy: 50.12%\n","Mean Accuracy: 50.212%\n","Standard Deviation: 0.6001799730080972%\n"]}],"source":["# k-Fold Cross-Validation\n","\n","k = 5\n","kf = KFold(n_splits=k)\n","accuracies = []\n","\n","for train_idx, test_idx in kf.split(dataset):\n","    train_subset = Subset(dataset, train_idx)\n","    test_subset = Subset(dataset, test_idx)\n","\n","    train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n","    test_loader = DataLoader(test_subset, batch_size=64, shuffle=False)\n","\n","    model = SimpleNN()\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","    for epoch in range(5):\n","        model.train()\n","        for images, labels in train_loader:\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = 100 * correct / total\n","    accuracies.append(accuracy)\n","    print(f'Fold Accuracy: {accuracy}%')\n","\n","print(f'Mean Accuracy: {np.mean(accuracies)}%')\n","print(f'Standard Deviation: {np.std(accuracies)}%')"]},{"cell_type":"markdown","metadata":{"id":"V9_6p3EI9l4r"},"source":["Explanation: A simple neural network with three linear layers and ReLU activations is defined.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"cEa6Snij9l4s"},"source":["### Exercise 2: Dropout Regularization\n","\n","#### Goal\n","\n","Apply dropout regularization to a neural network to improve its robustness.\n","\n","#### Instructions\n","\n","1.  **Data Preparation:**\n","    \n","    *   Use the same dataset as in Exercise 1.\n","2.  **Network Definition:**\n","    \n","    *   Define a neural network with multiple layers using `torch.nn.Module`.\n","    *   Add dropout layers after each hidden layer using `torch.nn.Dropout`.\n","3.  **Training and Evaluation:**\n","    \n","    *   Train the model on the training dataset, evaluating on a separate validation set.\n","    *   Experiment with different dropout rates (e.g., 0.2, 0.5, 0.7).\n","    *   Observe how dropout affects the model's performance, especially underfitting and overfitting.\n","4.  **Analysis:**\n","    \n","    *   Plot training and validation accuracy curves for different dropout rates.\n","    *   Discuss the results, noting any significant changes in accuracy or overfitting."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":13,"status":"aborted","timestamp":1714767113029,"user":{"displayName":"Pedro Patiño Garcia","userId":"11861007922219825640"},"user_tz":-120},"id":"TmbtzsBU9l4s"},"outputs":[],"source":["# Red Neuronal con Dropout\n","class DropoutCNN(nn.Module):\n","    def __init__(self, dropout_rate):\n","        super(DropoutCNN, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n","        self.fc1 = nn.Linear(16 * 16 * 16, 120)\n","        self.dropout = nn.Dropout(0.5)\n","        self.fc2 = nn.Linear(120, 10)\n","\n","    def forward(self, x):\n","        x = torch.relu(self.conv1(x))\n","        x = self.pool(x)\n","        x = x.view(-1, 16 * 16 * 16)\n","        x = torch.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        return x\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":14,"status":"aborted","timestamp":1714767113030,"user":{"displayName":"Pedro Patiño Garcia","userId":"11861007922219825640"},"user_tz":-120},"id":"uXzqKZCe9l4s"},"outputs":[{"name":"stdout","output_type":"stream","text":["dropout_rates:  [0.2, 0.5, 0.7]\n","accuracies:  [53.12, 53.118, 52.682]\n"]}],"source":["def train_evaluate(dropout_rate):\n","    model = DropoutCNN(dropout_rate)\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.SGD(model.parameters(), lr=0.01)\n","    train_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n","    test_loader = DataLoader(dataset, batch_size=64, shuffle=False)\n","\n","    for epoch in range(5):\n","        model.train()\n","        for images, labels in train_loader:\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    return 100 * correct / total\n","\n","# Evaluacion con diferentes ratios dropout\n","dropout_rates = [0.2, 0.5, 0.7]\n","accuracies = [train_evaluate(rate) for rate in dropout_rates]\n","\n","print(\"dropout_rates: \",dropout_rates)\n","print(\"accuracies: \",accuracies)"]},{"cell_type":"markdown","metadata":{"id":"mdLhTokD9l4s"},"source":["### Exercise 3: L1 Regularization\n","\n","#### Goal\n","\n","Implement L1 regularization to constrain model weights and reduce overfitting.\n","\n","#### Instructions\n","\n","1.  **Data Preparation:**\n","    \n","    *   Use the same dataset as in Exercise 1.\n","2.  **Network Definition:**\n","    \n","    *   Define a neural network with at least one hidden layer using `torch.nn.Module`.\n","3.  **L1 Regularization Implementation:**\n","    \n","    *   Add L1 regularization to the loss function by including the sum of the absolute values of model weights.\n","    *   Manually calculate the L1 loss and add it to the main loss function.\n","4.  **Training and Evaluation:**\n","    \n","    *   Train the model with and without L1 regularization.\n","    *   Compare the results in terms of overfitting and weight sparsity.\n","5.  **Analysis:**\n","    *   Plot weight histograms to visualize the effect of L1 regularization.\n","    *   Report accuracy and loss for both regularized and non-regularized models."]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":14,"status":"aborted","timestamp":1714767113031,"user":{"displayName":"Pedro Patiño Garcia","userId":"11861007922219825640"},"user_tz":-120},"id":"TBsLqoaT9l4t"},"outputs":[],"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(3, 32, 3)\n","        self.conv2 = nn.Conv2d(32, 64, 3)\n","        self.conv3 = nn.Conv2d(64, 128, 3)\n","        self.conv4 = nn.Conv2d(128, 256, 3)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(256 * 2 * 2, 512)\n","        self.fc2 = nn.Linear(512, 256)\n","        self.fc3 = nn.Linear(256, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = self.pool(F.relu(self.conv3(x)))\n","        x = self.pool(F.relu(self.conv4(x)))\n","        x = torch.flatten(x, 1)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","net = Net()\n"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"QkDjUNZ29l4t"},"outputs":[{"ename":"RuntimeError","evalue":"Calculated padded input size per channel: (2 x 2). Kernel size: (3 x 3). Kernel size can't be greater than actual input size","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[23], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 12\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Regularización L1\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\ppatinog\\miniconda3\\envs\\NLP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\ppatinog\\miniconda3\\envs\\NLP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[1;32mIn[22], line 17\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)))\n\u001b[0;32m     16\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x)))\n\u001b[1;32m---> 17\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     18\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     19\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n","File \u001b[1;32mc:\\Users\\ppatinog\\miniconda3\\envs\\NLP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\ppatinog\\miniconda3\\envs\\NLP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\ppatinog\\miniconda3\\envs\\NLP\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\ppatinog\\miniconda3\\envs\\NLP\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (2 x 2). Kernel size: (3 x 3). Kernel size can't be greater than actual input size"]}],"source":["# Función de pérdida\n","criterion = nn.CrossEntropyLoss()\n","\n","# Optimizador\n","optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n","\n","for epoch in range(10):  # Cuanto mas pongamos, mas acuracy\n","    running_loss = 0.0\n","    for i, data in enumerate(train_loader, 0):\n","        inputs, labels = data\n","        optimizer.zero_grad()\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        \n","        # Regularización L1\n","        l1_lambda = 0.001\n","        l1_loss = 0\n","        for param in net.parameters():\n","            l1_loss += torch.norm(param, 1)\n","        loss += l1_lambda * l1_loss\n","        \n","        loss.backward()\n","        optimizer.step()\n","        \n","        running_loss += loss.item()\n","        if i % 2000 == 1999:\n","            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n","            running_loss = 0.0\n","print('Finished Training')"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1714767113033,"user":{"displayName":"Pedro Patiño Garcia","userId":"11861007922219825640"},"user_tz":-120},"id":"_y0WuXFmvp2K"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of the network on the 10000 test images: 9 %\n"]}],"source":["correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in test_loader:\n","        images, labels = data\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}
