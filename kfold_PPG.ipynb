{"cells":[{"cell_type":"markdown","metadata":{"id":"dbIzUsii9l4l"},"source":["*   **Data Preparation:**\n","    \n","    *   Use any small dataset of your choice from `torchvision`, such as CIFAR-10.\n","    *   Prepare data loaders using `torch.utils.data.DataLoader`.\n","*   **k-Fold Cross-Validation Implementation:**\n","    \n","    *   Create a function that implements k-fold cross-validation.\n","    *   Split the dataset into k folds, training on k-1 folds, and testing on the remaining fold.\n","    *   Compute the accuracy of the model for each fold.\n","*   **Network Definition:**\n","    \n","    *   Define a simple neural network with at least one hidden layer using `torch.nn.Module`.\n","*   **Training and Evaluation:**\n","    \n","    *   For each fold, train the model on the training data and evaluate on the validation data.\n","    *   Report the mean and standard deviation of the accuracy across all folds."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16558,"status":"ok","timestamp":1714767131479,"user":{"displayName":"Pedro Patiño Garcia","userId":"11861007922219825640"},"user_tz":-120},"id":"Rziooxdt9l4p","outputId":"d196efe5-a9a4-4849-f674-494689a705dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["100.0%\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data\\cifar-10-python.tar.gz to ./data\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, Subset\n","from sklearn.model_selection import KFold\n","import numpy as np\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1714767131480,"user":{"displayName":"Pedro Patiño Garcia","userId":"11861007922219825640"},"user_tz":-120},"id":"rMAytW-U9l4r"},"outputs":[],"source":["class SimpleNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleNN, self).__init__()\n","        self.fc1 = nn.Linear(32 * 32 * 3, 128)\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, 10)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 32 * 32 * 3)\n","        x = torch.relu(self.fc1(x))\n","        x = torch.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":425},"executionInfo":{"elapsed":377982,"status":"error","timestamp":1714767509455,"user":{"displayName":"Pedro Patiño Garcia","userId":"11861007922219825640"},"user_tz":-120},"id":"skK3uu0pybKb","outputId":"84e37ff2-85b4-4163-8324-52437e25282c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold Accuracy: 50.29%\n","Fold Accuracy: 49.28%\n","Fold Accuracy: 51.17%\n","Fold Accuracy: 50.2%\n","Fold Accuracy: 50.12%\n","Mean Accuracy: 50.212%\n","Standard Deviation: 0.6001799730080972%\n"]}],"source":["# k-Fold Cross-Validation\n","\n","k = 5\n","kf = KFold(n_splits=k)\n","accuracies = []\n","\n","for train_idx, test_idx in kf.split(dataset):\n","    train_subset = Subset(dataset, train_idx)\n","    test_subset = Subset(dataset, test_idx)\n","\n","    train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n","    test_loader = DataLoader(test_subset, batch_size=64, shuffle=False)\n","\n","    model = SimpleNN()\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","    for epoch in range(5):\n","        model.train()\n","        for images, labels in train_loader:\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = 100 * correct / total\n","    accuracies.append(accuracy)\n","    print(f'Fold Accuracy: {accuracy}%')\n","\n","print(f'Mean Accuracy: {np.mean(accuracies)}%')\n","print(f'Standard Deviation: {np.std(accuracies)}%')"]},{"cell_type":"markdown","metadata":{"id":"V9_6p3EI9l4r"},"source":["Explanation: A simple neural network with three linear layers and ReLU activations is defined.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"cEa6Snij9l4s"},"source":["### Exercise 2: Dropout Regularization\n","\n","#### Goal\n","\n","Apply dropout regularization to a neural network to improve its robustness.\n","\n","#### Instructions\n","\n","1.  **Data Preparation:**\n","    \n","    *   Use the same dataset as in Exercise 1.\n","2.  **Network Definition:**\n","    \n","    *   Define a neural network with multiple layers using `torch.nn.Module`.\n","    *   Add dropout layers after each hidden layer using `torch.nn.Dropout`.\n","3.  **Training and Evaluation:**\n","    \n","    *   Train the model on the training dataset, evaluating on a separate validation set.\n","    *   Experiment with different dropout rates (e.g., 0.2, 0.5, 0.7).\n","    *   Observe how dropout affects the model's performance, especially underfitting and overfitting.\n","4.  **Analysis:**\n","    \n","    *   Plot training and validation accuracy curves for different dropout rates.\n","    *   Discuss the results, noting any significant changes in accuracy or overfitting."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":13,"status":"aborted","timestamp":1714767113029,"user":{"displayName":"Pedro Patiño Garcia","userId":"11861007922219825640"},"user_tz":-120},"id":"TmbtzsBU9l4s"},"outputs":[],"source":["# Red Neuronal con Dropout\n","class DropoutCNN(nn.Module):\n","    def __init__(self, dropout_rate):\n","        super(DropoutCNN, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n","        self.fc1 = nn.Linear(16 * 16 * 16, 120)\n","        self.dropout = nn.Dropout(0.5)\n","        self.fc2 = nn.Linear(120, 10)\n","\n","    def forward(self, x):\n","        x = torch.relu(self.conv1(x))\n","        x = self.pool(x)\n","        x = x.view(-1, 16 * 16 * 16)\n","        x = torch.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        return x\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":14,"status":"aborted","timestamp":1714767113030,"user":{"displayName":"Pedro Patiño Garcia","userId":"11861007922219825640"},"user_tz":-120},"id":"uXzqKZCe9l4s"},"outputs":[{"name":"stdout","output_type":"stream","text":["dropout_rates:  [0.2, 0.5, 0.7]\n","accuracies:  [53.12, 53.118, 52.682]\n"]}],"source":["def train_evaluate(dropout_rate):\n","    model = DropoutCNN(dropout_rate)\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.SGD(model.parameters(), lr=0.01)\n","    train_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n","    test_loader = DataLoader(dataset, batch_size=64, shuffle=False)\n","\n","    for epoch in range(5):\n","        model.train()\n","        for images, labels in train_loader:\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    return 100 * correct / total\n","\n","# Evaluacion con diferentes ratios dropout\n","dropout_rates = [0.2, 0.5, 0.7]\n","accuracies = [train_evaluate(rate) for rate in dropout_rates]\n","\n","print(\"dropout_rates: \",dropout_rates)\n","print(\"accuracies: \",accuracies)"]},{"cell_type":"markdown","metadata":{"id":"mdLhTokD9l4s"},"source":["### Exercise 3: L1 Regularization\n","\n","#### Goal\n","\n","Implement L1 regularization to constrain model weights and reduce overfitting.\n","\n","#### Instructions\n","\n","1.  **Data Preparation:**\n","    \n","    *   Use the same dataset as in Exercise 1.\n","2.  **Network Definition:**\n","    \n","    *   Define a neural network with at least one hidden layer using `torch.nn.Module`.\n","3.  **L1 Regularization Implementation:**\n","    \n","    *   Add L1 regularization to the loss function by including the sum of the absolute values of model weights.\n","    *   Manually calculate the L1 loss and add it to the main loss function.\n","4.  **Training and Evaluation:**\n","    \n","    *   Train the model with and without L1 regularization.\n","    *   Compare the results in terms of overfitting and weight sparsity.\n","5.  **Analysis:**\n","    *   Plot weight histograms to visualize the effect of L1 regularization.\n","    *   Report accuracy and loss for both regularized and non-regularized models."]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":14,"status":"aborted","timestamp":1714767113031,"user":{"displayName":"Pedro Patiño Garcia","userId":"11861007922219825640"},"user_tz":-120},"id":"TBsLqoaT9l4t"},"outputs":[],"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(3, 6, 5)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = torch.flatten(x, 1)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","net = Net()"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"QkDjUNZ29l4t"},"outputs":[{"name":"stdout","output_type":"stream","text":["Finished Training\n"]}],"source":["# Función de pérdida\n","criterion = nn.CrossEntropyLoss()\n","\n","# Definimos el optimizador con una tasa de aprendizaje más baja\n","optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n","\n","# Aumentamos el número de épocas de entrenamiento\n","num_epochs = 20\n","\n","for epoch in range(num_epochs):  \n","    running_loss = 0.0\n","    for i, data in enumerate(train_loader, 0):\n","        inputs, labels = data\n","        optimizer.zero_grad()\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        \n","        # Regularización L1\n","        l1_lambda = 0.001\n","        l1_loss = 0\n","        for param in net.parameters():\n","            l1_loss += torch.norm(param, 1)\n","        loss += l1_lambda * l1_loss\n","        \n","        loss.backward()\n","        optimizer.step()\n","        \n","        running_loss += loss.item()\n","        if i % 2000 == 1999:\n","            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n","            running_loss = 0.0\n","print('Finished Training')"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1714767113033,"user":{"displayName":"Pedro Patiño Garcia","userId":"11861007922219825640"},"user_tz":-120},"id":"_y0WuXFmvp2K"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of the network on the 10000 test images: 54 %\n"]}],"source":["correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in test_loader:\n","        images, labels = data\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}
